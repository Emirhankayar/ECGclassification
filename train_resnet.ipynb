{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 21:51:38.235308: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-01 21:51:38.243840: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743537098.253567  100050 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743537098.256352  100050 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743537098.264444  100050 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743537098.264463  100050 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743537098.264464  100050 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743537098.264465  100050 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-01 21:51:38.267332: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import Modules.constants as constants\n",
    "import Modules.ds_loader as ds_loader\n",
    "\n",
    "SAMPLE_PERCENTAGE = 1.0\n",
    "\n",
    "DATA_PATH = constants.DATASET\n",
    "TRAIN_DIR = DATA_PATH / \"train\"\n",
    "VAL_DIR = DATA_PATH / \"val\"\n",
    "TEST_DIR = DATA_PATH / \"test\"\n",
    "\n",
    "X_train, y_train = ds_loader.load_all_data(TRAIN_DIR, SAMPLE_PERCENTAGE)\n",
    "X_val, y_val = ds_loader.load_all_data(VAL_DIR, SAMPLE_PERCENTAGE)\n",
    "X_test, y_test = ds_loader.load_all_data(TEST_DIR, SAMPLE_PERCENTAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes in y: [0 1 2 3]\n",
      "float32\n",
      "int32\n",
      "Datatype: None None\n",
      "(8502, 10, 12) (532, 10, 12) (1594, 10, 12)\n",
      "(8502,) (532,) (1594,)\n",
      "Min and Max of X_train: 0.0, 1.0000009536743164\n",
      "Min and Max of X_test: -94.44111633300781, 192.52906799316406\n",
      "Min and Max of X_val: -223.99363708496094, 127.48966979980469\n",
      "NaNs in X: 0\n",
      "Infs in X: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique classes in y:\", np.unique(y_train))\n",
    "print(\"Datatype:\", print(X_train.dtype), print(y_train.dtype))\n",
    "print(X_train.shape, X_test.shape, X_val.shape)\n",
    "print(y_train.shape, y_test.shape, y_val.shape)\n",
    "print(f\"Min and Max of X_train: {np.min(X_train)}, {np.max(X_train)}\")\n",
    "print(f\"Min and Max of X_test: {np.min(X_test)}, {np.max(X_test)}\")\n",
    "print(f\"Min and Max of X_val: {np.min(X_val)}, {np.max(X_val)}\")\n",
    "print(f\"NaNs in X: {np.isnan(X_train).sum()}\")\n",
    "print(f\"Infs in X: {np.isinf(X_train).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-D convolutional ResNet model \n",
    "# https://pmc.ncbi.nlm.nih.gov/articles/PMC10128986/#sec012\n",
    "class Resnet(keras_tuner.HyperModel):\n",
    "    def residual_block(self, inputs, filters, kernel_size):\n",
    "        shortcut = tf.keras.layers.Conv1D(filters=filters, kernel_size=1, padding='same')(inputs)\n",
    "        \n",
    "        x = tf.keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, strides=1, padding='same')(inputs)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = tf.keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, strides=1, padding='same')(x)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        \n",
    "        # SKIP CONNECTION\n",
    "        x = tf.keras.layers.Add()([x, shortcut]) \n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "        x = tf.keras.layers.MaxPooling1D(pool_size=5, strides=2)(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def build(self, hp):\n",
    "        c_units = hp.Int('c_units', min_value=4, max_value=64, step=2)\n",
    "        d_units = hp.Int('d_units', min_value=4, max_value=128, step=2)\n",
    "        dropout = hp.Float('dropout', min_value = 0.4, max_value=0.5)\n",
    "        lr = hp.Float('lr', min_value=0.00001, max_value=0.001)\n",
    "        n = hp.Choice('#_res_layers', [1,2,3])\n",
    "        k_units = hp.Int('k_units', min_value=3, max_value=15, step=1)\n",
    "        m = hp.Float('momentum', min_value=0.1, max_value=0.9, step=0.1)\n",
    "        # INPUT LAYER\n",
    "        inputs = tf.keras.Input(shape=(500,12))\n",
    "        \n",
    "        # RESIDUALS\n",
    "        x = self.residual_block(inputs, filters=c_units, kernel_size=k_units)\n",
    "        for _ in range(n):  \n",
    "            x = self.residual_block(x, filters=c_units, kernel_size=k_units)\n",
    "        \n",
    "        # CLASSIFIER\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        x = tf.keras.layers.Dense(d_units, activation='relu')(x)\n",
    "        x = tf.keras.layers.Dropout(dropout)(x)  \n",
    "\n",
    "        x = tf.keras.layers.Dense(d_units // 2, activation='relu')(x)\n",
    "        x = tf.keras.layers.Dropout(dropout)(x)  \n",
    "\n",
    "        # OUTPUT\n",
    "        outputs = tf.keras.layers.Dense(4, activation='softmax')(x)\n",
    "\n",
    "        model = tf.keras.Model(inputs, outputs)\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.SGD(learning_rate=lr, momentum=m),\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"]\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        return model.fit(\n",
    "            epochs = hp.Int(\"epochs\", 10, 150, 10),\n",
    "            batch_size= hp.Choice(\"batch_size\", [16, 32, 64]),\n",
    "            *args,\n",
    "            **kwargs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trial 15 summary\n",
    "Hyperparameters:\n",
    "c_units: 16\n",
    "d_units: 16\n",
    "dropout: 0.4\n",
    "lr: 0.007954238351337758\n",
    "#_res_layers: 3\n",
    "k_units: 9\n",
    "epochs: 80\n",
    "batch_size: 16\n",
    "Score: 0.409099817276001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from Results/RESNET/ECGClassification/tuner0.json\n",
      "Search space summary\n",
      "Default search space size: 9\n",
      "c_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 4, 'max_value': 64, 'step': 2, 'sampling': 'linear'}\n",
      "d_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 4, 'max_value': 128, 'step': 2, 'sampling': 'linear'}\n",
      "dropout (Float)\n",
      "{'default': 0.4, 'conditions': [], 'min_value': 0.4, 'max_value': 0.5, 'step': None, 'sampling': 'linear'}\n",
      "lr (Float)\n",
      "{'default': 1e-05, 'conditions': [], 'min_value': 1e-05, 'max_value': 0.001, 'step': None, 'sampling': 'linear'}\n",
      "#_res_layers (Choice)\n",
      "{'default': 1, 'conditions': [], 'values': [1, 2, 3], 'ordered': True}\n",
      "k_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 3, 'max_value': 15, 'step': 1, 'sampling': 'linear'}\n",
      "momentum (Float)\n",
      "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.9, 'step': 0.1, 'sampling': 'linear'}\n",
      "epochs (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 10, 'max_value': 150, 'step': 10, 'sampling': 'linear'}\n",
      "batch_size (Choice)\n",
      "{'default': 16, 'conditions': [], 'values': [16, 32, 64], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner = keras_tuner.RandomSearch(\n",
    "    Resnet(),\n",
    "    max_trials=100,\n",
    "    objective='val_loss',\n",
    "    directory=\"Results/RESNET\",\n",
    "    project_name=\"ECGClassification\",\n",
    "    )\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "38                |38                |c_units\n",
      "78                |78                |d_units\n",
      "0.45305           |0.45305           |dropout\n",
      "0.00056706        |0.00056706        |lr\n",
      "3                 |3                 |#_res_layers\n",
      "5                 |5                 |k_units\n",
      "0.3               |0.3               |momentum\n",
      "90                |90                |epochs\n",
      "32                |32                |batch_size\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743537102.354780  100050 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1347 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n",
      "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 239, in _run_and_update_trial\n",
      "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n",
      "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n",
      "    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_100050/539608629.py\", line 62, in fit\n",
      "    return model.fit(\n",
      "           ^^^^^^^^^^\n",
      "  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras/src/layers/input_spec.py\", line 245, in assert_input_compatibility\n",
      "    raise ValueError(\n",
      "ValueError: Input 0 of layer \"functional\" is incompatible with the layer: expected shape=(None, 500, 12), found shape=(None, 10, 12)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 239, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_100050/539608629.py\", line 62, in fit\n    return model.fit(\n           ^^^^^^^^^^\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras/src/layers/input_spec.py\", line 245, in assert_input_compatibility\n    raise ValueError(\nValueError: Input 0 of layer \"functional\" is incompatible with the layer: expected shape=(None, 500, 12), found shape=(None, 10, 12)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m callback_list = [\n\u001b[32m      2\u001b[39m     tf.keras.callbacks.EarlyStopping(monitor=\u001b[33m\"\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m\"\u001b[39m, patience=\u001b[32m10\u001b[39m, verbose=\u001b[32m0\u001b[39m)\n\u001b[32m      3\u001b[39m ]\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mtuner\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback_list\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:235\u001b[39m, in \u001b[36mBaseTuner.search\u001b[39m\u001b[34m(self, *fit_args, **fit_kwargs)\u001b[39m\n\u001b[32m    233\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_trial_begin(trial)\n\u001b[32m    234\u001b[39m     \u001b[38;5;28mself\u001b[39m._try_run_and_update_trial(trial, *fit_args, **fit_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mon_trial_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[38;5;28mself\u001b[39m.on_search_end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:339\u001b[39m, in \u001b[36mBaseTuner.on_trial_end\u001b[39m\u001b[34m(self, trial)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mon_trial_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial):\n\u001b[32m    334\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Called at the end of a trial.\u001b[39;00m\n\u001b[32m    335\u001b[39m \n\u001b[32m    336\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    337\u001b[39m \u001b[33;03m        trial: A `Trial` instance.\u001b[39;00m\n\u001b[32m    338\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moracle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    340\u001b[39m     \u001b[38;5;28mself\u001b[39m.save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/oracle.py:108\u001b[39m, in \u001b[36msynchronized.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    106\u001b[39m     LOCKS[oracle].acquire()\n\u001b[32m    107\u001b[39m     THREADS[oracle] = thread_name\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m ret_val = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m need_acquire:\n\u001b[32m    110\u001b[39m     THREADS[oracle] = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/oracle.py:588\u001b[39m, in \u001b[36mOracle.end_trial\u001b[39m\u001b[34m(self, trial)\u001b[39m\n\u001b[32m    586\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retry(trial):\n\u001b[32m    587\u001b[39m     \u001b[38;5;28mself\u001b[39m.end_order.append(trial.trial_id)\n\u001b[32m--> \u001b[39m\u001b[32m588\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_consecutive_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    590\u001b[39m \u001b[38;5;28mself\u001b[39m._save_trial(trial)\n\u001b[32m    591\u001b[39m \u001b[38;5;28mself\u001b[39m.save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/oracle.py:545\u001b[39m, in \u001b[36mOracle._check_consecutive_failures\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    543\u001b[39m     consecutive_failures = \u001b[32m0\u001b[39m\n\u001b[32m    544\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m consecutive_failures == \u001b[38;5;28mself\u001b[39m.max_consecutive_failed_trials:\n\u001b[32m--> \u001b[39m\u001b[32m545\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    546\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNumber of consecutive failures exceeded the limit \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    547\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mof \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.max_consecutive_failed_trials\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    548\u001b[39m         + (trial.message \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    549\u001b[39m     )\n",
      "\u001b[31mRuntimeError\u001b[39m: Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 239, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_100050/539608629.py\", line 62, in fit\n    return model.fit(\n           ^^^^^^^^^^\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras/src/layers/input_spec.py\", line 245, in assert_input_compatibility\n    raise ValueError(\nValueError: Input 0 of layer \"functional\" is incompatible with the layer: expected shape=(None, 500, 12), found shape=(None, 10, 12)\n"
     ]
    }
   ],
   "source": [
    "callback_list = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, verbose=0)\n",
    "]\n",
    "\n",
    "tuner.search(\n",
    "    X_train, y_train, \n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=callback_list \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tuner.get_best_models(num_models=1)\n",
    "best_model = models[0]\n",
    "best_model.summary()\n",
    "best_model.save(\"Results/BEST_RESNET_00.h5\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESNET50 WITH BOTTLENECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class Resnet50(tf.keras.Model):\n",
    "    \n",
    "    def bottleneck_block(self, inputs, filters=16, strides=1):\n",
    "        # First convolution (1x1)\n",
    "        x = tf.keras.layers.Conv1D(filters=filters, kernel_size=1, strides=strides, padding='same')(inputs)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        \n",
    "        # Second convolution (3x3)\n",
    "        x = tf.keras.layers.Conv1D(filters=filters, kernel_size=3, padding='same')(x)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        \n",
    "        # Third convolution (1x1)\n",
    "        x = tf.keras.layers.Conv1D(filters=filters * 4, kernel_size=1, padding='same')(x)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        \n",
    "        # Shortcut path (1x1 convolution if necessary)\n",
    "        shortcut = tf.keras.layers.Conv1D(filters=filters * 4, kernel_size=1, strides=strides, padding='same')(inputs)\n",
    "        \n",
    "        # Add the shortcut to the residual output\n",
    "        x = tf.keras.layers.Add()([x, shortcut])\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def build(self, hp):\n",
    "        c_units = hp.Int('c_units', min_value=16, max_value=64, step=16)  # Increased filter size for ResNet50-like architecture\n",
    "        d_units = hp.Int('d_units', min_value=64, max_value=256, step=64)\n",
    "        dropout = hp.Float('dropout', min_value=0.3, max_value=0.5, step=0.1)\n",
    "        lr = hp.Float('lr', min_value=1e-4, max_value=1e-2)\n",
    "        n = hp.Choice('#_res_layers', [2, 3, 4])  # You can experiment with the number of residual layers\n",
    "        \n",
    "        # INPUT LAYER\n",
    "        inputs = tf.keras.Input(shape=(5000, 12))  # Shape of input\n",
    "\n",
    "        # First Convolution (For initial feature extraction)\n",
    "        x = tf.keras.layers.Conv1D(filters=c_units, kernel_size=7, strides=2, padding='same')(inputs)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        \n",
    "        # First Residual Block (typically after initial conv)\n",
    "        x = self.bottleneck_block(x, filters=c_units)\n",
    "        \n",
    "        # Additional Residual Blocks (stacked)\n",
    "        for _ in range(n):  \n",
    "            x = self.bottleneck_block(x, filters=c_units)\n",
    "\n",
    "        # Global Average Pooling (typically used in ResNet50)\n",
    "        x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "        \n",
    "        # CLASSIFIER\n",
    "        x = tf.keras.layers.Dense(d_units, activation='relu')(x)\n",
    "        x = tf.keras.layers.Dropout(dropout)(x)\n",
    "        \n",
    "        x = tf.keras.layers.Dense(d_units // 2, activation='relu')(x)\n",
    "        x = tf.keras.layers.Dropout(dropout)(x)\n",
    "\n",
    "        # OUTPUT\n",
    "        outputs = tf.keras.layers.Dense(4, activation='softmax')(x)\n",
    "\n",
    "        model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"]\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        return model.fit(\n",
    "            epochs = hp.Int(\"epochs\", 50, 100, 10),\n",
    "            batch_size= hp.Choice(\"batch_size\", [4, 8, 16, 32]),\n",
    "            *args,\n",
    "            **kwargs,\n",
    "        )\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = best_model.evaluate(X_test, y_test, batch_size=32)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)  \n",
    "auc = sklearn.metrics.roc_auc_score(y_test, y_pred, multi_class='ovr')\n",
    "\n",
    "print(\"Classification Report (Test Data):\")\n",
    "print(sklearn.metrics.classification_report(y_test, y_pred))\n",
    "print(f\"AUC: {auc}\")\n",
    "\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_train_pred = np.argmax(y_train_pred, axis=1)\n",
    "\n",
    "print(\"Classification Report (Train Data):\")\n",
    "print(sklearn.metrics.classification_report(y_train, y_train_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0] \n",
    "print(best_hps.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0] \n",
    "modified_hps = best_hps.copy()\n",
    "\n",
    "#modified_hps.values['c_units'] = 16\n",
    "#modified_hps.values['k_units'] = 5 \n",
    "#best_model = Resnet().build(modified_hps)\n",
    "\n",
    "#best_model = Resnet().build(best_hps)\n",
    "#best_model = RNN().build(best_hps)\n",
    "best_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.5),\n",
    "                   loss='sparse_categorical_crossentropy',\n",
    "                   metrics=['accuracy']) \n",
    "history = best_model.fit(\n",
    "    X_train, y_train, \n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=150,\n",
    "    batch_size=16\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = best_model.evaluate(X_test, y_test, batch_size=16)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)  \n",
    "auc = sklearn.metrics.roc_auc_score(y_test, y_pred, multi_class='ovr')\n",
    "\n",
    "print(\"Classification Report (Test Data):\")\n",
    "print(sklearn.metrics.classification_report(y_test, y_pred))\n",
    "print(f\"AUC: {auc}\")\n",
    "\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_train_pred = np.argmax(y_train_pred, axis=1)\n",
    "\n",
    "print(\"Classification Report (Train Data):\")\n",
    "print(sklearn.metrics.classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "ax[0].plot(history.history['accuracy'], label='accuracy')\n",
    "ax[0].plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "ax[0].set_title('Accuracy vs Val Accuracy')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(history.history['loss'], label='loss')\n",
    "ax[1].plot(history.history['val_loss'], label='val_loss')\n",
    "ax[1].set_title('Loss vs Val Loss')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
