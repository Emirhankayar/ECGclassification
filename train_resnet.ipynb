{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 20:42:53.325345: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-03 20:42:53.461253: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743705773.528739   34166 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743705773.549037   34166 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743705773.733470   34166 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743705773.733523   34166 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743705773.733526   34166 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743705773.733528   34166 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-03 20:42:53.746488: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras_tuner\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import Modules.constants as constants\n",
    "import Modules.ds_loader as ds_loader\n",
    "\n",
    "SAMPLE_PERCENTAGE = 1.0\n",
    "\n",
    "DATA_PATH = constants.DATASET\n",
    "TRAIN_DIR = DATA_PATH / \"train\"\n",
    "VAL_DIR = DATA_PATH / \"val\"\n",
    "TEST_DIR = DATA_PATH / \"test\"\n",
    "\n",
    "X_train, y_train = ds_loader.load_all_data(TRAIN_DIR, SAMPLE_PERCENTAGE)\n",
    "X_val, y_val = ds_loader.load_all_data(VAL_DIR, SAMPLE_PERCENTAGE)\n",
    "X_test, y_test = ds_loader.load_all_data(TEST_DIR, SAMPLE_PERCENTAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes in y: [0 1 2 3]\n",
      "float32\n",
      "int32\n",
      "Datatype: None None\n",
      "(8502, 500, 12) (532, 500, 12) (1594, 500, 12)\n",
      "(8502,) (532,) (1594,)\n",
      "Min and Max of X_train: 0.0, 1.0000001192092896\n",
      "Min and Max of X_test: -7.487946510314941, 9.202398300170898\n",
      "Min and Max of X_val: -8.297019004821777, 8.205255508422852\n",
      "NaNs in X: 0\n",
      "Infs in X: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique classes in y:\", np.unique(y_train))\n",
    "print(\"Datatype:\", print(X_train.dtype), print(y_train.dtype))\n",
    "print(X_train.shape, X_test.shape, X_val.shape)\n",
    "print(y_train.shape, y_test.shape, y_val.shape)\n",
    "print(f\"Min and Max of X_train: {np.min(X_train)}, {np.max(X_train)}\")\n",
    "print(f\"Min and Max of X_test: {np.min(X_test)}, {np.max(X_test)}\")\n",
    "print(f\"Min and Max of X_val: {np.min(X_val)}, {np.max(X_val)}\")\n",
    "print(f\"NaNs in X: {np.isnan(X_train).sum()}\")\n",
    "print(f\"Infs in X: {np.isinf(X_train).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-D convolutional ResNet model \n",
    "# https://pmc.ncbi.nlm.nih.gov/articles/PMC10128986/#sec012\n",
    "class Resnet(keras_tuner.HyperModel):\n",
    "    def residual_block(self, inputs, c_units_1, c_units_2, kernel_size):\n",
    "        shortcut = tf.keras.layers.Conv1D(filters=c_units_2, kernel_size=1, padding='same')(inputs)\n",
    "        \n",
    "        x = tf.keras.layers.Conv1D(filters=c_units_1, kernel_size=kernel_size, strides=1, padding='same')(inputs)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = tf.keras.layers.Conv1D(filters=c_units_2, kernel_size=kernel_size, strides=1, padding='same')(x)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        \n",
    "        # SKIP CONNECTION\n",
    "        x = tf.keras.layers.Add()([x, shortcut]) \n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "        x = tf.keras.layers.MaxPooling1D(pool_size=5, strides=2)(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def build(self, hp):\n",
    "        c_units_1 = hp.Int('c_units_1', min_value=8, max_value=128, step=2)\n",
    "        c_units_2 = hp.Int('c_units_2', min_value=8, max_value=128, step=2)\n",
    "        d_units_1 = hp.Int('d_units_1', min_value=8, max_value=128, step=2)\n",
    "        d_units_2 = hp.Int('d_units_2', min_value=8, max_value=128, step=2)\n",
    "        dropout_1 = hp.Float('dropout_1', min_value = 0.2, max_value=0.5)\n",
    "        dropout_2 = hp.Float('dropout_2', min_value = 0.2, max_value=0.5)\n",
    "        n = hp.Choice('#_res_layers', [1,2,3,4])\n",
    "        k_units = hp.Int('k_units', min_value=3, max_value=15, step=1)\n",
    "        # INPUT LAYER\n",
    "        inputs = tf.keras.Input(shape=(500,12))\n",
    "        \n",
    "        # RESIDUALS\n",
    "        x = self.residual_block(inputs, c_units_1, c_units_2, kernel_size=k_units)\n",
    "        for _ in range(n):  \n",
    "            x = self.residual_block(x, c_units_1, c_units_2, kernel_size=k_units)\n",
    "\n",
    "        # CLASSIFIER\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        x = tf.keras.layers.Dense(d_units_1, activation='relu')(x)\n",
    "        x = tf.keras.layers.Dropout(dropout_1)(x)  \n",
    "\n",
    "        x = tf.keras.layers.Dense(d_units_2, activation='relu')(x)\n",
    "        x = tf.keras.layers.Dropout(dropout_2)(x)  \n",
    "\n",
    "        # OUTPUT\n",
    "        outputs = tf.keras.layers.Dense(4, activation='softmax')(x)\n",
    "        \n",
    "        optimizer_choice = hp.Choice('optimizer', ['adam', 'sgd'])\n",
    "        \n",
    "        if optimizer_choice == 'adam':\n",
    "            optimizer = tf.keras.optimizers.Adam(\n",
    "                learning_rate=hp.Float('r_learning', min_value=1e-5, max_value=1e-3, sampling='LOG')\n",
    "            )\n",
    "        elif optimizer_choice == 'sgd':\n",
    "            optimizer = tf.keras.optimizers.SGD(\n",
    "                learning_rate=hp.Float('r_learning', min_value=1e-5, max_value=1e-3, sampling='LOG'),\n",
    "                momentum=hp.Float('momentum', min_value=0.0, max_value=0.9, step=0.05)\n",
    "            )\n",
    "\n",
    "        model = tf.keras.Model(inputs, outputs)\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"]\n",
    "        )\n",
    "        \n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        return model.fit(\n",
    "            epochs = hp.Int(\"epochs\", 10, 200, 10),\n",
    "            batch_size= hp.Choice(\"batch_size\", [16, 32, 64, 128]),\n",
    "            *args,\n",
    "            **kwargs,\n",
    "        ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trial 15 summary\n",
    "Hyperparameters:\n",
    "c_units: 16\n",
    "d_units: 16\n",
    "dropout: 0.4\n",
    "lr: 0.007954238351337758\n",
    "#_res_layers: 3\n",
    "k_units: 9\n",
    "epochs: 80\n",
    "batch_size: 16\n",
    "Score: 0.409099817276001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from Results/RESNET/ECGClassification/tuner0.json\n",
      "Search space summary\n",
      "Default search space size: 13\n",
      "c_units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 8, 'max_value': 128, 'step': 2, 'sampling': 'linear'}\n",
      "c_units_2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 8, 'max_value': 128, 'step': 2, 'sampling': 'linear'}\n",
      "d_units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 8, 'max_value': 128, 'step': 2, 'sampling': 'linear'}\n",
      "d_units_2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 8, 'max_value': 128, 'step': 2, 'sampling': 'linear'}\n",
      "dropout_1 (Float)\n",
      "{'default': 0.2, 'conditions': [], 'min_value': 0.2, 'max_value': 0.5, 'step': None, 'sampling': 'linear'}\n",
      "dropout_2 (Float)\n",
      "{'default': 0.2, 'conditions': [], 'min_value': 0.2, 'max_value': 0.5, 'step': None, 'sampling': 'linear'}\n",
      "#_res_layers (Choice)\n",
      "{'default': 1, 'conditions': [], 'values': [1, 2, 3, 4], 'ordered': True}\n",
      "k_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 3, 'max_value': 15, 'step': 1, 'sampling': 'linear'}\n",
      "optimizer (Choice)\n",
      "{'default': 'adam', 'conditions': [], 'values': ['adam', 'sgd'], 'ordered': False}\n",
      "r_learning (Float)\n",
      "{'default': 1e-05, 'conditions': [], 'min_value': 1e-05, 'max_value': 0.001, 'step': None, 'sampling': 'log'}\n",
      "momentum (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.9, 'step': 0.05, 'sampling': 'linear'}\n",
      "epochs (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 10, 'max_value': 200, 'step': 10, 'sampling': 'linear'}\n",
      "batch_size (Choice)\n",
      "{'default': 16, 'conditions': [], 'values': [16, 32, 64, 128], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner = keras_tuner.RandomSearch(\n",
    "    Resnet(),\n",
    "    max_trials=100,\n",
    "    objective='val_loss',\n",
    "    directory=\"Results/RESNET\",\n",
    "    project_name=\"ECGClassification\",\n",
    "    )\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "42                |84                |c_units_1\n",
      "68                |40                |c_units_2\n",
      "24                |74                |d_units_1\n",
      "10                |84                |d_units_2\n",
      "0.34823           |0.35623           |dropout_1\n",
      "0.25042           |0.49117           |dropout_2\n",
      "1                 |1                 |#_res_layers\n",
      "12                |3                 |k_units\n",
      "adam              |sgd               |optimizer\n",
      "1.0035e-05        |0.00015975        |r_learning\n",
      "0.05              |0.4               |momentum\n",
      "150               |70                |epochs\n",
      "64                |64                |batch_size\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743705788.748631   34166 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4097 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1743705792.597783   34376 service.cc:152] XLA service 0x7ff6ec014890 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1743705792.597805   34376 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 4050 Laptop GPU, Compute Capability 8.9\n",
      "2025-04-03 20:43:12.695818: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "E0000 00:00:1743705793.149417   34376 cuda_dnn.cc:522] Loaded runtime CuDNN library: 9.1.0 but source was compiled with: 9.3.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "E0000 00:00:1743705793.261438   34376 cuda_dnn.cc:522] Loaded runtime CuDNN library: 9.1.0 but source was compiled with: 9.3.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2025-04-03 20:43:13.272077: W tensorflow/core/framework/op_kernel.cc:1857] OP_REQUIRES failed at xla_ops.cc:591 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "2025-04-03 20:43:13.272127: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "\t [[{{node StatefulPartitionedCall}}]]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n",
      "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 239, in _run_and_update_trial\n",
      "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n",
      "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n",
      "    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_34166/1346138573.py\", line 76, in fit\n",
      "    return model.fit(\n",
      "           ^^^^^^^^^^\n",
      "  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\n",
      "    except TypeError as e:\n",
      "tensorflow.python.framework.errors_impl.FailedPreconditionError: Graph execution error:\n",
      "\n",
      "Detected at node StatefulPartitionedCall defined at (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "\n",
      "  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "\n",
      "  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "\n",
      "  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "\n",
      "  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "\n",
      "  File \"/usr/lib64/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "\n",
      "  File \"/usr/lib64/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "\n",
      "  File \"/usr/lib64/python3.11/asyncio/events.py\", line 84, in _run\n",
      "\n",
      "  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "\n",
      "  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "\n",
      "  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "\n",
      "  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "\n",
      "  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "\n",
      "  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "\n",
      "  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "\n",
      "  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3047, in run_cell\n",
      "\n",
      "  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3102, in _run_cell\n",
      "\n",
      "  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "\n",
      "  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3306, in run_cell_async\n",
      "\n",
      "  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3489, in run_ast_nodes\n",
      "\n",
      "  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3549, in run_code\n",
      "\n",
      "  File \"/tmp/ipykernel_34166/874603744.py\", line 5, in <module>\n",
      "\n",
      "  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 234, in search\n",
      "\n",
      "  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n",
      "\n",
      "  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 239, in _run_and_update_trial\n",
      "\n",
      "  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n",
      "\n",
      "  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n",
      "\n",
      "  File \"/tmp/ipykernel_34166/1346138573.py\", line 76, in fit\n",
      "\n",
      "  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
      "\n",
      "  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n",
      "\n",
      "  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n",
      "\n",
      "  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n",
      "\n",
      "DNN library initialization failed. Look at the errors above for more details.\n",
      "\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_6341]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 239, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_34166/1346138573.py\", line 76, in fit\n    return model.fit(\n           ^^^^^^^^^^\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\n    except TypeError as e:\ntensorflow.python.framework.errors_impl.FailedPreconditionError: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib64/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/usr/lib64/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/usr/lib64/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3047, in run_cell\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3102, in _run_cell\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3306, in run_cell_async\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3489, in run_ast_nodes\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3549, in run_code\n\n  File \"/tmp/ipykernel_34166/874603744.py\", line 5, in <module>\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 234, in search\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 239, in _run_and_update_trial\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n\n  File \"/tmp/ipykernel_34166/1346138573.py\", line 76, in fit\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\nDNN library initialization failed. Look at the errors above for more details.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_6341]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m callback_list = [\n\u001b[32m      2\u001b[39m     tf.keras.callbacks.EarlyStopping(monitor=\u001b[33m\"\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m\"\u001b[39m, patience=\u001b[32m10\u001b[39m, verbose=\u001b[32m0\u001b[39m)\n\u001b[32m      3\u001b[39m ]\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mtuner\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback_list\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:235\u001b[39m, in \u001b[36mBaseTuner.search\u001b[39m\u001b[34m(self, *fit_args, **fit_kwargs)\u001b[39m\n\u001b[32m    233\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_trial_begin(trial)\n\u001b[32m    234\u001b[39m     \u001b[38;5;28mself\u001b[39m._try_run_and_update_trial(trial, *fit_args, **fit_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mon_trial_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[38;5;28mself\u001b[39m.on_search_end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:339\u001b[39m, in \u001b[36mBaseTuner.on_trial_end\u001b[39m\u001b[34m(self, trial)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mon_trial_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial):\n\u001b[32m    334\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Called at the end of a trial.\u001b[39;00m\n\u001b[32m    335\u001b[39m \n\u001b[32m    336\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    337\u001b[39m \u001b[33;03m        trial: A `Trial` instance.\u001b[39;00m\n\u001b[32m    338\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moracle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    340\u001b[39m     \u001b[38;5;28mself\u001b[39m.save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/oracle.py:108\u001b[39m, in \u001b[36msynchronized.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    106\u001b[39m     LOCKS[oracle].acquire()\n\u001b[32m    107\u001b[39m     THREADS[oracle] = thread_name\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m ret_val = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m need_acquire:\n\u001b[32m    110\u001b[39m     THREADS[oracle] = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/oracle.py:588\u001b[39m, in \u001b[36mOracle.end_trial\u001b[39m\u001b[34m(self, trial)\u001b[39m\n\u001b[32m    586\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retry(trial):\n\u001b[32m    587\u001b[39m     \u001b[38;5;28mself\u001b[39m.end_order.append(trial.trial_id)\n\u001b[32m--> \u001b[39m\u001b[32m588\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_consecutive_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    590\u001b[39m \u001b[38;5;28mself\u001b[39m._save_trial(trial)\n\u001b[32m    591\u001b[39m \u001b[38;5;28mself\u001b[39m.save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/oracle.py:545\u001b[39m, in \u001b[36mOracle._check_consecutive_failures\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    543\u001b[39m     consecutive_failures = \u001b[32m0\u001b[39m\n\u001b[32m    544\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m consecutive_failures == \u001b[38;5;28mself\u001b[39m.max_consecutive_failed_trials:\n\u001b[32m--> \u001b[39m\u001b[32m545\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    546\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNumber of consecutive failures exceeded the limit \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    547\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mof \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.max_consecutive_failed_trials\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    548\u001b[39m         + (trial.message \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    549\u001b[39m     )\n",
      "\u001b[31mRuntimeError\u001b[39m: Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 239, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_34166/1346138573.py\", line 76, in fit\n    return model.fit(\n           ^^^^^^^^^^\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\n    except TypeError as e:\ntensorflow.python.framework.errors_impl.FailedPreconditionError: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib64/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/usr/lib64/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/usr/lib64/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3047, in run_cell\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3102, in _run_cell\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3306, in run_cell_async\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3489, in run_ast_nodes\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3549, in run_code\n\n  File \"/tmp/ipykernel_34166/874603744.py\", line 5, in <module>\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 234, in search\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 239, in _run_and_update_trial\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n\n  File \"/tmp/ipykernel_34166/1346138573.py\", line 76, in fit\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/home/capitan/.venv/tenv/lib64/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\nDNN library initialization failed. Look at the errors above for more details.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_6341]\n"
     ]
    }
   ],
   "source": [
    "callback_list = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, verbose=0)\n",
    "]\n",
    "\n",
    "tuner.search(\n",
    "    X_train, y_train, \n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=callback_list \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tuner.get_best_models(num_models=1)\n",
    "best_model = models[0]\n",
    "best_model.summary()\n",
    "best_model.save(\"Results/BEST_RESNET_05.h5\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESNET50 WITH BOTTLENECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class Resnet50(tf.keras.Model):\n",
    "    \n",
    "    def bottleneck_block(self, inputs, filters=16, strides=1):\n",
    "        # First convolution (1x1)\n",
    "        x = tf.keras.layers.Conv1D(filters=filters, kernel_size=1, strides=strides, padding='same')(inputs)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        \n",
    "        # Second convolution (3x3)\n",
    "        x = tf.keras.layers.Conv1D(filters=filters, kernel_size=3, padding='same')(x)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        \n",
    "        # Third convolution (1x1)\n",
    "        x = tf.keras.layers.Conv1D(filters=filters * 4, kernel_size=1, padding='same')(x)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        \n",
    "        # Shortcut path (1x1 convolution if necessary)\n",
    "        shortcut = tf.keras.layers.Conv1D(filters=filters * 4, kernel_size=1, strides=strides, padding='same')(inputs)\n",
    "        \n",
    "        # Add the shortcut to the residual output\n",
    "        x = tf.keras.layers.Add()([x, shortcut])\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def build(self, hp):\n",
    "        c_units = hp.Int('c_units', min_value=16, max_value=64, step=16)  # Increased filter size for ResNet50-like architecture\n",
    "        d_units = hp.Int('d_units', min_value=64, max_value=256, step=64)\n",
    "        dropout = hp.Float('dropout', min_value=0.3, max_value=0.5, step=0.1)\n",
    "        lr = hp.Float('lr', min_value=1e-4, max_value=1e-2)\n",
    "        n = hp.Choice('#_res_layers', [2, 3, 4])  # You can experiment with the number of residual layers\n",
    "        \n",
    "        # INPUT LAYER\n",
    "        inputs = tf.keras.Input(shape=(5000, 12))  # Shape of input\n",
    "\n",
    "        # First Convolution (For initial feature extraction)\n",
    "        x = tf.keras.layers.Conv1D(filters=c_units, kernel_size=7, strides=2, padding='same')(inputs)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        \n",
    "        # First Residual Block (typically after initial conv)\n",
    "        x = self.bottleneck_block(x, filters=c_units)\n",
    "        \n",
    "        # Additional Residual Blocks (stacked)\n",
    "        for _ in range(n):  \n",
    "            x = self.bottleneck_block(x, filters=c_units)\n",
    "\n",
    "        # Global Average Pooling (typically used in ResNet50)\n",
    "        x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "        \n",
    "        # CLASSIFIER\n",
    "        x = tf.keras.layers.Dense(d_units, activation='relu')(x)\n",
    "        x = tf.keras.layers.Dropout(dropout)(x)\n",
    "        \n",
    "        x = tf.keras.layers.Dense(d_units // 2, activation='relu')(x)\n",
    "        x = tf.keras.layers.Dropout(dropout)(x)\n",
    "\n",
    "        # OUTPUT\n",
    "        outputs = tf.keras.layers.Dense(4, activation='softmax')(x)\n",
    "\n",
    "        model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"]\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        return model.fit(\n",
    "            epochs = hp.Int(\"epochs\", 50, 100, 10),\n",
    "            batch_size= hp.Choice(\"batch_size\", [4, 8, 16, 32]),\n",
    "            *args,\n",
    "            **kwargs,\n",
    "        )\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = best_model.evaluate(X_test, y_test, batch_size=32)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "if y_pred.shape[1] == 1:  \n",
    "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, y_pred)  \n",
    "else:\n",
    "    y_pred_binary = np.argmax(y_pred, axis=1)  \n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, y_pred, multi_class='ovr')\n",
    "\n",
    "print(\"Classification Report (Test Data):\")\n",
    "print(sklearn.metrics.classification_report(y_test, y_pred_binary))\n",
    "print(f\"AUC: {auc}\")\n",
    "\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_train_pred = np.argmax(y_train_pred, axis=1)\n",
    "\n",
    "print(\"Classification Report (Train Data):\")\n",
    "print(sklearn.metrics.classification_report(y_train, y_train_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0] \n",
    "print(best_hps.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0] \n",
    "modified_hps = best_hps.copy()\n",
    "\n",
    "modified_hps.values['c_units_1'] = 8\n",
    "modified_hps.values['c_units_2'] = 16\n",
    "modified_hps.values['d_units_1'] = 32\n",
    "modified_hps.values['d_units_2'] = 64\n",
    "modified_hps.values['k_units'] = 5\n",
    "modified_hps.values['#_res_layers'] = 3\n",
    "modified_hps.values['dropout'] = 0.3\n",
    "#best_model = Resnet().build(modified_hps)\n",
    "\n",
    "best_model = Resnet().build(modified_hps)\n",
    "#best_model = RNN().build(best_hps)\n",
    "best_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.005, momentum=0.9),\n",
    "                   loss='sparse_categorical_crossentropy',\n",
    "                   metrics=['accuracy']) \n",
    "history = best_model.fit(\n",
    "    X_train, y_train, \n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=60,\n",
    "    batch_size=128\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = best_model.evaluate(X_test, y_test, batch_size=16)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "if y_pred.shape[1] == 1:  \n",
    "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, y_pred)  \n",
    "else:\n",
    "    y_pred_binary = np.argmax(y_pred, axis=1)  \n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, y_pred, multi_class='ovr')\n",
    "\n",
    "print(\"Classification Report (Test Data):\")\n",
    "print(sklearn.metrics.classification_report(y_test, y_pred_binary))\n",
    "print(f\"AUC: {auc}\")\n",
    "\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_train_pred = np.argmax(y_train_pred, axis=1)\n",
    "\n",
    "print(\"Classification Report (Train Data):\")\n",
    "print(sklearn.metrics.classification_report(y_train, y_train_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "ax[0].plot(history.history['accuracy'], label='accuracy')\n",
    "ax[0].plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "ax[0].set_title('Accuracy vs Val Accuracy')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(history.history['loss'], label='loss')\n",
    "ax[1].plot(history.history['val_loss'], label='val_loss')\n",
    "ax[1].set_title('Loss vs Val Loss')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
